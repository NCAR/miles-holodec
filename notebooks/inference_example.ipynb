{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ff86707-cc39-4df1-a6b2-edef5cca34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "from scipy.signal import convolve2d\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import xarray as xr\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch, scipy\n",
    "import torch.fft\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from holodec.transforms import LoadTransformations\n",
    "from holodec.propagation import WavePropagator\n",
    "\n",
    "# from holodecml.seed import seed_everything\n",
    "from holodec.datasets import LoadHolograms\n",
    "from holodec.unet import load_model\n",
    "from holodec.losses import load_loss\n",
    "\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import xarray as xr\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import torch.fft\n",
    "import logging\n",
    "import shutil\n",
    "import random\n",
    "import psutil\n",
    "import optuna\n",
    "import torch\n",
    "import time\n",
    "import tqdm\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "from holodecml.metrics import DistributedROC\n",
    "from hagelslag.evaluation.MetricPlotter import roc_curve, performance_diagram\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e329c8d7-b121-4f59-88d2-2857deac148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0677629-00c3-4278-b01f-0d5c83c0af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196a54d2-b374-4ac0-8e66-d8914c2145da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_training.nc\"\n",
    "test_dataset_path = \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_validation.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43b8edd-ab47-4a88-8e91-e6bd3075eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_file_path = \"/glade/work/schreck/repos/HOLO/style/holodec-ml/results/manopt/model.yml\" #\"../results/batch7/model.yml\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0dc0a7-ae03-4770-88ec-f5bb607affea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(conf_file_path) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12591449-a488-49bd-9ae8-485fffe0b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(conf[\"model\"])\n",
    "model_dict = torch.load(\"/glade/work/schreck/repos/HOLO/style/holodec-ml/results/manopt/best.pt\")[\"model_state_dict\"]\n",
    "model.load_state_dict(model_dict)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb1449b8-7252-4383-b523-fcbea1a670a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead = 2 #int(conf[\"data\"][\"lookahead\"])\n",
    "conf[\"model\"][\"in_channels\"] = 2 #* (lookahead + 1)\n",
    "\n",
    "n_bins = int(conf[\"data\"][\"n_bins\"])\n",
    "tile_size = int(conf[\"data\"][\"tile_size\"])\n",
    "step_size = int(conf[\"data\"][\"step_size\"])\n",
    "\n",
    "train_dataset = LoadHolograms(\n",
    "    \"/glade/p/cisl/aiml/ai4ess_hackathon/holodec/synthetic_holograms_500particle_gamma_4872x3248_training.nc\",\n",
    "    shuffle=False,\n",
    "    device=\"cpu\",\n",
    "    n_bins=n_bins,\n",
    "    transform=None,#LoadTransformations(conf[\"transforms\"][\"training\"]),\n",
    "    lookahead=lookahead,\n",
    "    tile_size=tile_size,\n",
    "    step_size=step_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72cc0c1-5654-46fd-a57e-6cba9ddaea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id 32016\n"
     ]
    }
   ],
   "source": [
    "random_integer = random.randint(0, train_dataset.__len__())\n",
    "print(\"Id\", random_integer)\n",
    "x, part_mask, depth_mask, weight_mask = train_dataset.__getitem__(random_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b451ebd8-ca59-41af-82d2-f18a1b3d3db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4872, 3248]) torch.Size([4872, 3248])\n",
      "Mask sum tensor(74., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, part_mask.shape)\n",
    "print(\"Mask sum\", part_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3ee821-c9c6-4274-a0e6-b164695b6a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x150d889ff430>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(part_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5c9962-16d1-4ece-a59b-214b8f78538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model(x[0:1].to(device)[:, :4832, :3232].unsqueeze(0) / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44b8515b-c89e-4248-b895-b3e0ea6d956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferencePropagator(WavePropagator):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 n_bins=n_bins,\n",
    "                 color_dim=1,\n",
    "                 tile_size=512,\n",
    "                 step_size=128,\n",
    "                 marker_size=10,\n",
    "                 transform_mode=None,\n",
    "                 device=\"cuda\",\n",
    "                 model=None,\n",
    "                 transforms=None,\n",
    "                 mode=None,\n",
    "                 probability_threshold=0.5):\n",
    "\n",
    "        super(InferencePropagator, self).__init__(\n",
    "            data_path,\n",
    "            n_bins=n_bins,\n",
    "            tile_size=tile_size,\n",
    "            step_size=step_size,\n",
    "            marker_size=marker_size,\n",
    "            transform_mode=transform_mode,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.color_dim = color_dim\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.probability_threshold = probability_threshold\n",
    "        self.create_mapping()\n",
    "\n",
    "    def create_mapping(self):\n",
    "\n",
    "        self.idx2slice = {}\n",
    "        for row_idx in range(self.Nx//self.step_size):\n",
    "\n",
    "            if row_idx*self.step_size+self.tile_size > self.Nx:\n",
    "                image_pixel_x = self.Nx-self.tile_size\n",
    "                row_slice = slice(-self.tile_size, None)\n",
    "                row_break = True\n",
    "            else:\n",
    "                image_pixel_x = row_idx*self.step_size\n",
    "                row_slice = slice(row_idx*self.step_size,\n",
    "                                  row_idx*self.step_size+self.tile_size)\n",
    "                row_break = False\n",
    "\n",
    "            for col_idx in range(self.Ny//self.step_size):\n",
    "\n",
    "                if col_idx*self.step_size+self.tile_size > self.Ny:\n",
    "                    image_pixel_y = self.Ny-self.tile_size\n",
    "                    col_slice = slice(-self.tile_size, None)\n",
    "                    col_break = True\n",
    "                else:\n",
    "                    image_pixel_y = col_idx*self.step_size\n",
    "                    col_slice = slice(col_idx*self.step_size,\n",
    "                                      col_idx*self.step_size+self.tile_size)\n",
    "                    col_break = False\n",
    "\n",
    "                self.idx2slice[row_idx, col_idx] = (row_slice, col_slice)\n",
    "\n",
    "                if col_break:\n",
    "                    break\n",
    "\n",
    "            if row_break:\n",
    "                break\n",
    "\n",
    "    def get_sub_images_labeled(self,\n",
    "                               image_tnsr,\n",
    "                               z_sub_set,\n",
    "                               z_counter,\n",
    "                               xp, yp, zp, dp,\n",
    "                               infocus_mask,\n",
    "                               z_part_bin_idx,\n",
    "                               batch_size=32,\n",
    "                               return_arrays=False,\n",
    "                               return_metrics=False,\n",
    "                               thresholds=None,\n",
    "                               obs_threshold=None):\n",
    "        \"\"\"\n",
    "        Reconstruct z_sub_set planes from\n",
    "        the original hologram image and\n",
    "        split it into tiles of size\n",
    "        tile_size\n",
    "\n",
    "        image - 3D tensor on device to reconstruct\n",
    "        z_sub_set - array of z planes to reconstruct in one batch\n",
    "        z_counter - counter of how many z images have been reconstructed\n",
    "\n",
    "        Returns \n",
    "            Esub - a list of complex tiled images \n",
    "            image_index_lst - tile index of the sub image (x,y,z)\n",
    "            image_corner_coords - x,y coordinates of the tile corner (starting values)\n",
    "            z_pos - the z position of the plane in m\n",
    "        \"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # build the torch tensor for reconstruction\n",
    "            z_plane = torch.tensor(\n",
    "                z_sub_set*1e-6, device=self.device).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "            # reconstruct the selected planes\n",
    "            E_out = self.torch_holo_set(image_tnsr, z_plane)\n",
    "\n",
    "            if self.color_dim == 2:\n",
    "                stacked_image = torch.cat([\n",
    "                    torch.abs(E_out).unsqueeze(1), torch.angle(E_out).unsqueeze(1)], 1)\n",
    "            elif self.color_dim == 1:\n",
    "                stacked_image = torch.abs(E_out).unsqueeze(1)\n",
    "            else:\n",
    "                raise OSError(f\"Unrecognized color dimension {self.color_dim}\")\n",
    "            stacked_image = self.apply_transforms(\n",
    "                stacked_image.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "            size = (E_out.shape[1], E_out.shape[2])\n",
    "            true_output = torch.zeros(size).to(self.device)\n",
    "            pred_output = torch.zeros(size).to(self.device)\n",
    "            pred_proba = torch.zeros(size).to(self.device)\n",
    "            counter = torch.zeros(size).to(self.device)\n",
    "\n",
    "            chunked = np.array_split(\n",
    "                list(self.idx2slice.items()),\n",
    "                int(np.ceil(len(self.idx2slice) / batch_size))\n",
    "            )\n",
    "\n",
    "            for z_idx in range(E_out.shape[0]):\n",
    "\n",
    "                unet_mask = torch.zeros(E_out.shape[1:]).to(\n",
    "                    self.device)  # initialize the UNET mask\n",
    "                # locate all particles in this plane\n",
    "                part_in_plane_idx = np.where(\n",
    "                    z_part_bin_idx == z_idx+z_counter)[0]\n",
    "\n",
    "                # build the UNET mask for this z plane\n",
    "                for part_idx in part_in_plane_idx:\n",
    "                    unet_mask += torch.from_numpy(\n",
    "                        (self.y_arr[None, :]*1e6-yp[part_idx])**2 +\n",
    "                        (self.x_arr[:, None]*1e6-xp[part_idx]\n",
    "                         )**2 < (dp[part_idx]/2)**2\n",
    "                    ).float().to(self.device)\n",
    "\n",
    "                worker = partial(\n",
    "                    self.collate_masks,\n",
    "                    image=stacked_image[z_idx, :].float(),\n",
    "                    mask=unet_mask\n",
    "                )\n",
    "\n",
    "                for chunk in chunked:\n",
    "                    slices, x, true_mask_tile = worker(chunk)\n",
    "                    pred_proba_tile = self.model(x).squeeze(1)\n",
    "                    pred_mask_tile = pred_proba_tile > self.probability_threshold\n",
    "\n",
    "                    for k, ((row_idx, col_idx), (row_slice, col_slice)) in enumerate(slices):\n",
    "                        counter[row_slice, col_slice] += 1\n",
    "                        true_output[row_slice,\n",
    "                                    col_slice] += true_mask_tile[k]\n",
    "                        pred_output[row_slice,\n",
    "                                    col_slice] += pred_mask_tile[k]\n",
    "                        pred_proba[row_slice,\n",
    "                                   col_slice] += pred_proba_tile[k]\n",
    "\n",
    "            return_dict = {\"z\": int(round(z_sub_set[0]))}\n",
    "                                        \n",
    "            # Compute the (x,y,d) of predicted masks\n",
    "            pred_output = pred_output == counter\n",
    "            true_output = true_output == counter\n",
    "            \n",
    "            true_coordinates = []\n",
    "            if true_output.sum() > 0:\n",
    "                arr, n = scipy.ndimage.label(true_output.cpu())\n",
    "                _centroid = scipy.ndimage.find_objects(arr)\n",
    "                for particle in _centroid:\n",
    "                    xind = (particle[0].stop + particle[0].start) // 2\n",
    "                    yind = (particle[1].stop + particle[1].start) // 2\n",
    "                    dind = max([\n",
    "                        abs(particle[0].stop - particle[0].start), \n",
    "                        abs(particle[1].stop - particle[1].start)\n",
    "                    ])\n",
    "                    true_coordinates.append([xind,yind,int(round(z_sub_set[0])),dind])\n",
    "\n",
    "            pred_coordinates = []\n",
    "            if pred_output.sum() > 0:\n",
    "                arr, n = scipy.ndimage.label(pred_output.cpu())\n",
    "                _centroid = scipy.ndimage.find_objects(arr)\n",
    "                for particle in _centroid:\n",
    "                    xind = (particle[0].stop + particle[0].start) // 2\n",
    "                    yind = (particle[1].stop + particle[1].start) // 2\n",
    "                    dind = max([\n",
    "                        abs(particle[0].stop - particle[0].start), \n",
    "                        abs(particle[1].stop - particle[1].start)\n",
    "                    ])\n",
    "                    pred_coordinates.append([xind,yind,int(round(z_sub_set[0])),dind])\n",
    "            \n",
    "            return_dict[\"pred_output\"] = pred_coordinates\n",
    "            return_dict[\"true_output\"] = true_coordinates\n",
    "            \n",
    "            if return_arrays:\n",
    "                return_dict[\"pred_array\"] = pred_output\n",
    "                return_dict[\"pred_proba\"] = pred_proba\n",
    "                return_dict[\"true_array\"] = true_output\n",
    "                \n",
    "            if return_metrics:\n",
    "                pred_output = pred_output.cpu().numpy()\n",
    "                pred_proba = pred_proba.cpu().numpy()\n",
    "                true_output = true_output.cpu().numpy()\n",
    "                roc = DistributedROC(thresholds=thresholds,\n",
    "                                     obs_threshold=obs_threshold)\n",
    "                roc.update(pred_proba.ravel(), true_output.ravel())\n",
    "                return_dict[\"roc\"] = roc\n",
    "            \n",
    "        return return_dict\n",
    "\n",
    "    def collate_labels(self, batch, image=None, label=None):\n",
    "        x, y = zip(*[\n",
    "            (image[:, row_slice, col_slice],\n",
    "             torch.LongTensor([int(label[row_idx, col_idx])]))\n",
    "            for ((row_idx, col_idx), (row_slice, col_slice)) in batch\n",
    "        ])\n",
    "        return batch, torch.stack(x), torch.stack(y)  # / self.image_norm\n",
    "\n",
    "    def collate_masks(self, batch, image=None, mask=None):\n",
    "        x, y = zip(*[\n",
    "            (image[:, row_slice, col_slice], mask[row_slice, col_slice])\n",
    "            for ((row_idx, col_idx), (row_slice, col_slice)) in batch\n",
    "        ])\n",
    "        return batch, torch.stack(x), torch.stack(y)  # / self.image_norm\n",
    "\n",
    "    def apply_transforms(self, image):\n",
    "        if self.transforms:\n",
    "            im = {\"image\": image}\n",
    "            for image_transform in self.transforms:\n",
    "                im = image_transform(im)\n",
    "            image = im[\"image\"]\n",
    "        return image\n",
    "\n",
    "    def get_next_z_planes_labeled(self,\n",
    "                                  h_idx,\n",
    "                                  z_planes_lst,\n",
    "                                  batch_size=32,\n",
    "                                  return_arrays=False,\n",
    "                                  return_metrics=False,\n",
    "                                  thresholds=np.arange(0.0, 1.1, 0.1),\n",
    "                                  obs_threshold=1.0,\n",
    "                                  start_z_counter=0):\n",
    "        \"\"\"\n",
    "        Generator that returns reconstructed z patches\n",
    "        input_image - 2D image array of the original captured hologam \n",
    "        z_planes_lst - list containing batchs of arrays of z positions to reconstruct\n",
    "            create_z_plane_lst() will provide this for a desired batch size and set\n",
    "            planes\n",
    "\n",
    "        returns:\n",
    "            sub_image - list of sub images\n",
    "            image_index_lst - list of tile indicies to the sub image\n",
    "            image_coords - x,y corner coordinates of the sub images\n",
    "            image_z - z location of the sub image in m\n",
    "        \"\"\"\n",
    "        # locate particle information corresponding to this hologram\n",
    "        particle_idx = np.where(self.h_ds['hid'].values == h_idx+1)\n",
    "        \n",
    "        x_part = self.h_ds['x'].values[particle_idx]\n",
    "        y_part = self.h_ds['y'].values[particle_idx]\n",
    "        z_part = self.h_ds['z'].values[particle_idx]\n",
    "        d_part = self.h_ds['d'].values[particle_idx]  # not used but here it is\n",
    "        \n",
    "        # create a 3D histogram\n",
    "        in_data = np.stack((x_part, y_part, z_part)).T\n",
    "        h_part = np.histogramdd(\n",
    "            in_data, bins=[self.tile_x_bins, self.tile_y_bins, self.z_bins])[0]\n",
    "        # specify the z bin locations of the particles\n",
    "        z_part_bin_idx = np.digitize(z_part, self.z_bins)-1\n",
    "\n",
    "        # smoothing kernel accounts for overlapping subimages when the\n",
    "        # subimage is larger than the stride\n",
    "        if self.step_size < self.tile_size:\n",
    "            overlap_kernel = np.ones((\n",
    "                self.tile_size//self.step_size, self.tile_size//self.step_size\n",
    "            ))\n",
    "            for z_idx in range(h_part.shape[-1]):\n",
    "                b = self.tile_size//self.step_size\n",
    "                h_part[:, :, z_idx] = convolve2d(h_part[:, :, z_idx], overlap_kernel)[\n",
    "                    b-1:h_part.shape[0]+b-1, b-1:h_part.shape[1]+b-1]\n",
    "\n",
    "        input_image = self.h_ds['image'].isel(hologram_number=h_idx).values\n",
    "\n",
    "        z_counter = start_z_counter  # the number of planes reconstructed in this generator\n",
    "        image_tnsr = torch.tensor(input_image, device=self.device).unsqueeze(0)\n",
    "        z_planes_lst = self.create_z_plane_lst(z_planes_lst)\n",
    "        \n",
    "        for z_sub_set in z_planes_lst:\n",
    "            yield self.get_sub_images_labeled(\n",
    "                image_tnsr,\n",
    "                z_sub_set,\n",
    "                z_counter,\n",
    "                x_part, y_part, z_part, d_part, h_part,\n",
    "                z_part_bin_idx,\n",
    "                batch_size=batch_size,\n",
    "                return_arrays=return_arrays,\n",
    "                return_metrics=return_metrics,\n",
    "                thresholds=thresholds,\n",
    "                obs_threshold=obs_threshold\n",
    "            )\n",
    "            z_counter += z_sub_set.size\n",
    "\n",
    "            # clear the cached memory from the gpu\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    def create_z_plane_lst(self, z_planes_lst):\n",
    "        \"\"\"\n",
    "        Create a list of z planes according to the requested\n",
    "        batch size.  This generates the z_planes_lst argument\n",
    "        needed for gen_next_z_plane()\n",
    "        \"\"\"\n",
    "        z_lst = []\n",
    "        for z_idx in z_planes_lst:\n",
    "            z_lst.append(self.z_centers[z_idx:(z_idx+1)])\n",
    "        return z_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f16d3ea-530c-40c4-9f2d-2ee2a3f736ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = conf[\"inference\"][\"n_nodes\"]\n",
    "n_gpus = conf[\"inference\"][\"gpus_per_node\"]\n",
    "threads_per_gpu = conf[\"inference\"][\"threads_per_gpu\"]\n",
    "workers = int(n_nodes * n_gpus * threads_per_gpu)\n",
    "\n",
    "n_bins = conf[\"data\"][\"n_bins\"]\n",
    "tile_size = conf[\"data\"][\"tile_size\"]\n",
    "step_size = conf[\"data\"][\"step_size\"]\n",
    "marker_size = conf[\"data\"][\"marker_size\"]\n",
    "transform_mode = (\n",
    "    \"None\"\n",
    "    if \"transform_mode\" not in conf[\"data\"]\n",
    "    else conf[\"data\"][\"transform_mode\"]\n",
    ")\n",
    "\n",
    "model_loc = conf[\"save_loc\"]\n",
    "model_name = conf[\"model\"][\"name\"]\n",
    "color_dim = conf[\"model\"][\"in_channels\"]\n",
    "\n",
    "batch_size = conf[\"inference\"][\"batch_size\"]\n",
    "save_arrays = True\n",
    "save_metrics = True\n",
    "save_prob = conf[\"inference\"][\"save_probs\"]\n",
    "inference_mode = conf[\"inference\"][\"mode\"]\n",
    "\n",
    "if \"probability_threshold\" in conf[\"inference\"]:\n",
    "    probability_threshold = conf[\"inference\"][\"probability_threshold\"]\n",
    "else:\n",
    "    probability_threshold = 0.5\n",
    "\n",
    "verbose = conf[\"inference\"][\"verbose\"]\n",
    "data_set = conf[\"inference\"][\"data_set\"][\"path\"]\n",
    "data_set_name = conf[\"inference\"][\"data_set\"][\"name\"]\n",
    "\n",
    "prop_data_loc = os.path.join(model_loc, f\"{data_set_name}/propagated\")\n",
    "roc_data_loc = os.path.join(model_loc, f\"{data_set_name}/roc\")\n",
    "image_data_loc = os.path.join(model_loc, f\"{data_set_name}/images\")\n",
    "\n",
    "save_dirs = [prop_data_loc]\n",
    "\n",
    "# roc threshold\n",
    "obs_threshold = 1.0\n",
    "if conf[\"inference\"][\"data_set\"][\"name\"] == \"raw\":\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "else:\n",
    "    thresholds = 1.0 - np.logspace(\n",
    "        -5, 0, num=50, endpoint=True, base=10.0, dtype=None, axis=0\n",
    "    )\n",
    "    thresholds = thresholds[::-1]\n",
    "\n",
    "# Configuration settings for which holograms to process\n",
    "h_conf = conf[\"inference\"][\"data_set\"][\"holograms\"]\n",
    "if isinstance(h_conf, dict):\n",
    "    h_min = conf[\"inference\"][\"data_set\"][\"holograms\"][\"min\"]\n",
    "    h_max = conf[\"inference\"][\"data_set\"][\"holograms\"][\"max\"]\n",
    "    h_range = range(h_min, h_max)\n",
    "elif isinstance(h_conf, list):\n",
    "    h_range = h_conf\n",
    "elif isinstance(h_conf, int) or isinstance(h_conf, float):\n",
    "    h_range = [h_conf]\n",
    "else:\n",
    "    raise OSError(f\"Unidentified h-range settings {h_conf}\")\n",
    "\n",
    "# Load the image transformations\n",
    "if \"inference\" in conf[\"transforms\"]:\n",
    "    if \"Normalize\" in conf[\"transforms\"][\"training\"]:\n",
    "        conf[\"transforms\"][\"inference\"][\"Normalize\"][\"mode\"] = conf[\"transforms\"][\n",
    "            \"training\"\n",
    "        ][\"Normalize\"][\"mode\"]\n",
    "    tile_transforms = LoadTransformations(conf[\"transforms\"][\"inference\"])\n",
    "else:\n",
    "    tile_transforms = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59e2c61d-7656-4979-899c-1fc7cae4e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_range = [0]\n",
    "z_list = np.array(range(170, 220))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1381cef-14bc-423f-a477-78da7a933583",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FocalTverskyLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m pred_coors \u001b[38;5;241m=\u001b[39m results_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_output\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#total_roc.merge(results_dict[\"roc\"])\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mFocalTverskyLoss\u001b[49m()((results_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat(), results_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_array\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(z_idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m, true_coors, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPred\u001b[39m\u001b[38;5;124m\"\u001b[39m, pred_coors, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[1;32m     37\u001b[0m t\u001b[38;5;241m.\u001b[39mappend(results_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_array\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FocalTverskyLoss' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prop = InferencePropagator(\n",
    "        test_dataset_path,\n",
    "        n_bins=n_bins,\n",
    "        color_dim=color_dim,\n",
    "        tile_size=tile_size,\n",
    "        step_size=step_size,\n",
    "        marker_size=marker_size,\n",
    "        transform_mode=None,#transform_mode,\n",
    "        device=device,\n",
    "        model=model,\n",
    "        mode=inference_mode,\n",
    "        probability_threshold=probability_threshold,\n",
    "        transforms=None,#tile_transforms,\n",
    "    )\n",
    "\n",
    "    # Main loop to call the generator, predict with the model, and aggregate and save the results\n",
    "    #total_roc = DistributedROC(thresholds=thresholds, obs_threshold=obs_threshold)\n",
    "    for nc, h_idx in enumerate(h_range):\n",
    "        inference_generator = prop.get_next_z_planes_labeled(\n",
    "            h_idx,\n",
    "            z_list,\n",
    "            batch_size=batch_size,\n",
    "            thresholds=thresholds,\n",
    "            obs_threshold=obs_threshold,\n",
    "            start_z_counter=z_list[0],\n",
    "            return_arrays=True,\n",
    "            return_metrics=True\n",
    "        )\n",
    "        t, p = [], []\n",
    "        for z_idx, results_dict in enumerate(inference_generator):\n",
    "            true_coors = results_dict[\"true_output\"]\n",
    "            pred_coors = results_dict[\"pred_output\"]\n",
    "            #total_roc.merge(results_dict[\"roc\"])\n",
    "            #loss = FocalTverskyLoss()((results_dict[\"pred_proba\"] > 0.5).float(), results_dict[\"true_array\"].float())\n",
    "            print(z_idx, \"True\", true_coors, \"Pred\", pred_coors, \"Loss\", loss)\n",
    "            t.append(results_dict[\"true_array\"].float())\n",
    "            p.append(results_dict[\"pred_proba\"].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cb0f96d-332c-48ea-9f44-702e2d1ca83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2436, 1624, 38552, 4872],\n",
       " [5, 10, 38552, 6],\n",
       " [4, 18, 38552, 3],\n",
       " [4, 26, 38552, 3],\n",
       " [4, 30, 38552, 3],\n",
       " [3, 34, 38552, 1],\n",
       " [4, 42, 38552, 3],\n",
       " [3, 50, 38552, 1],\n",
       " [4, 58, 38552, 3],\n",
       " [3, 66, 38552, 1],\n",
       " [3, 74, 38552, 1],\n",
       " [3, 82, 38552, 1],\n",
       " [4, 90, 38552, 3],\n",
       " [3, 98, 38552, 1],\n",
       " [4, 106, 38552, 3],\n",
       " [4, 114, 38552, 3],\n",
       " [4, 122, 38552, 3],\n",
       " [3, 130, 38552, 1],\n",
       " [4, 138, 38552, 2],\n",
       " [3, 146, 38552, 1],\n",
       " [3, 154, 38552, 1],\n",
       " [3, 162, 38552, 1],\n",
       " [3, 170, 38552, 1],\n",
       " [3, 178, 38552, 1],\n",
       " [3, 186, 38552, 1],\n",
       " [3, 194, 38552, 1],\n",
       " [4, 202, 38552, 3],\n",
       " [4, 206, 38552, 3],\n",
       " [3, 210, 38552, 1],\n",
       " [3, 226, 38552, 1],\n",
       " [4, 234, 38552, 3],\n",
       " [5, 239, 38552, 4],\n",
       " [3, 242, 38552, 1],\n",
       " [4, 250, 38552, 3],\n",
       " [3, 258, 38552, 1],\n",
       " [3, 266, 38552, 1],\n",
       " [3, 274, 38552, 1],\n",
       " [4, 282, 38552, 3],\n",
       " [3, 290, 38552, 1],\n",
       " [4, 298, 38552, 3],\n",
       " [5, 303, 38552, 4],\n",
       " [3, 306, 38552, 1],\n",
       " [4, 314, 38552, 3],\n",
       " [3, 322, 38552, 1],\n",
       " [4, 330, 38552, 3],\n",
       " [3, 338, 38552, 1],\n",
       " [4, 346, 38552, 3],\n",
       " [5, 351, 38552, 4],\n",
       " [3, 354, 38552, 1],\n",
       " [3, 362, 38552, 1],\n",
       " [3, 370, 38552, 1],\n",
       " [3, 378, 38552, 1],\n",
       " [3, 386, 38552, 1],\n",
       " [4, 394, 38552, 3],\n",
       " [3, 402, 38552, 1],\n",
       " [3, 422, 38552, 1],\n",
       " [3, 426, 38552, 1],\n",
       " [3, 434, 38552, 1],\n",
       " [5, 445, 38552, 7],\n",
       " [4, 451, 38552, 3],\n",
       " [3, 458, 38552, 1],\n",
       " [3, 466, 38552, 1],\n",
       " [3, 474, 38552, 1],\n",
       " [3, 482, 38552, 1],\n",
       " [3, 490, 38552, 1],\n",
       " [3, 498, 38552, 1],\n",
       " [3, 514, 38552, 1],\n",
       " [4, 522, 38552, 3],\n",
       " [5, 526, 38552, 4],\n",
       " [3, 530, 38552, 1],\n",
       " [4, 538, 38552, 3],\n",
       " [4, 542, 38552, 3],\n",
       " [3, 554, 38552, 1],\n",
       " [4, 563, 38552, 3],\n",
       " [4, 567, 38552, 3],\n",
       " [4, 570, 38552, 2],\n",
       " [3, 578, 38552, 1],\n",
       " [3, 586, 38552, 1],\n",
       " [3, 594, 38552, 1],\n",
       " [3, 602, 38552, 1],\n",
       " [3, 610, 38552, 1],\n",
       " [3, 618, 38552, 1],\n",
       " [3, 626, 38552, 1],\n",
       " [3, 634, 38552, 1],\n",
       " [3, 642, 38552, 1],\n",
       " [3, 650, 38552, 1],\n",
       " [3, 658, 38552, 1],\n",
       " [3, 666, 38552, 1],\n",
       " [4, 682, 38552, 3],\n",
       " [4, 686, 38552, 3],\n",
       " [3, 690, 38552, 1],\n",
       " [4, 698, 38552, 3],\n",
       " [3, 706, 38552, 1],\n",
       " [4, 714, 38552, 3],\n",
       " [5, 718, 38552, 4],\n",
       " [3, 722, 38552, 1],\n",
       " [3, 738, 38552, 1],\n",
       " [3, 746, 38552, 1],\n",
       " [3, 750, 38552, 1],\n",
       " [4, 762, 38552, 3],\n",
       " [3, 766, 38552, 1],\n",
       " [3, 770, 38552, 1],\n",
       " [3, 778, 38552, 1],\n",
       " [3, 794, 38552, 1],\n",
       " [3, 802, 38552, 1],\n",
       " [5, 806, 38552, 4],\n",
       " [3, 810, 38552, 1],\n",
       " [4, 814, 38552, 3],\n",
       " [3, 818, 38552, 1],\n",
       " [3, 826, 38552, 1],\n",
       " [4, 830, 38552, 2],\n",
       " [3, 842, 38552, 1],\n",
       " [4, 850, 38552, 3],\n",
       " [3, 858, 38552, 1],\n",
       " [3, 866, 38552, 1],\n",
       " [4, 874, 38552, 3],\n",
       " [4, 879, 38552, 3],\n",
       " [3, 882, 38552, 1],\n",
       " [3, 890, 38552, 1],\n",
       " [3, 906, 38552, 1],\n",
       " [3, 914, 38552, 1],\n",
       " [3, 922, 38552, 1],\n",
       " [3, 930, 38552, 1],\n",
       " [4, 938, 38552, 3],\n",
       " [4, 942, 38552, 3],\n",
       " [3, 946, 38552, 1],\n",
       " [4, 954, 38552, 2],\n",
       " [4, 962, 38552, 3],\n",
       " [4, 970, 38552, 3],\n",
       " [4, 975, 38552, 3],\n",
       " [3, 978, 38552, 1],\n",
       " [3, 986, 38552, 1],\n",
       " [4, 994, 38552, 3],\n",
       " [3, 1002, 38552, 1],\n",
       " [4, 1006, 38552, 3],\n",
       " [3, 1010, 38552, 1],\n",
       " [3, 1026, 38552, 1],\n",
       " [3, 1034, 38552, 1],\n",
       " [4, 1042, 38552, 3],\n",
       " [3, 1050, 38552, 1],\n",
       " [4, 1078, 38552, 3],\n",
       " [3, 1082, 38552, 1],\n",
       " [3, 1086, 38552, 1],\n",
       " [3, 1090, 38552, 1],\n",
       " [4, 1098, 38552, 3],\n",
       " [5, 1103, 38552, 4],\n",
       " [3, 1106, 38552, 1],\n",
       " [3, 1114, 38552, 1],\n",
       " [3, 1138, 38552, 1],\n",
       " [3, 1154, 38552, 1],\n",
       " [3, 1162, 38552, 1],\n",
       " [3, 1166, 38552, 1],\n",
       " [3, 1170, 38552, 1],\n",
       " [3, 1178, 38552, 1],\n",
       " [3, 1186, 38552, 1],\n",
       " [4, 1190, 38552, 3],\n",
       " [3, 1194, 38552, 1],\n",
       " [3, 1202, 38552, 1],\n",
       " [4, 1218, 38552, 3],\n",
       " [3, 1234, 38552, 1],\n",
       " [4, 1242, 38552, 3],\n",
       " [3, 1250, 38552, 1],\n",
       " [4, 1258, 38552, 3],\n",
       " [3, 1262, 38552, 1],\n",
       " [4, 1282, 38552, 3],\n",
       " [3, 1290, 38552, 1],\n",
       " [3, 1298, 38552, 1],\n",
       " [4, 1306, 38552, 3],\n",
       " [3, 1314, 38552, 1],\n",
       " [4, 1322, 38552, 3],\n",
       " [5, 1326, 38552, 4],\n",
       " [3, 1330, 38552, 1],\n",
       " [4, 1338, 38552, 3],\n",
       " [3, 1346, 38552, 1],\n",
       " [3, 1354, 38552, 1],\n",
       " [3, 1362, 38552, 1],\n",
       " [3, 1370, 38552, 1],\n",
       " [3, 1386, 38552, 1],\n",
       " [3, 1394, 38552, 1],\n",
       " [3, 1402, 38552, 1],\n",
       " [3, 1410, 38552, 1],\n",
       " [4, 1418, 38552, 3],\n",
       " [3, 1426, 38552, 1],\n",
       " [3, 1434, 38552, 1],\n",
       " [4, 1442, 38552, 3],\n",
       " [4, 1450, 38552, 3],\n",
       " [3, 1466, 38552, 1],\n",
       " [3, 1474, 38552, 1],\n",
       " [4, 1482, 38552, 3],\n",
       " [3, 1498, 38552, 1],\n",
       " [3, 1506, 38552, 1],\n",
       " [4, 1518, 38552, 3],\n",
       " [3, 1522, 38552, 1],\n",
       " [4, 1530, 38552, 3],\n",
       " [5, 1535, 38552, 4],\n",
       " [3, 1538, 38552, 1],\n",
       " [3, 1546, 38552, 1],\n",
       " [4, 1562, 38552, 3],\n",
       " [4, 1578, 38552, 3],\n",
       " [3, 1586, 38552, 1],\n",
       " [4, 1594, 38552, 3],\n",
       " [4, 1598, 38552, 3],\n",
       " [4, 1610, 38552, 3],\n",
       " [3, 1618, 38552, 1],\n",
       " [3, 1626, 38552, 1],\n",
       " [3, 1634, 38552, 1],\n",
       " [4, 1646, 38552, 3],\n",
       " [3, 1650, 38552, 1],\n",
       " [3, 1658, 38552, 1],\n",
       " [4, 1674, 38552, 3],\n",
       " [4, 1690, 38552, 3],\n",
       " [3, 1698, 38552, 1],\n",
       " [4, 1706, 38552, 3],\n",
       " [4, 1710, 38552, 3],\n",
       " [3, 1714, 38552, 1],\n",
       " [3, 1722, 38552, 1],\n",
       " [3, 1726, 38552, 1],\n",
       " [4, 1738, 38552, 3],\n",
       " [4, 1743, 38552, 3],\n",
       " [3, 1746, 38552, 1],\n",
       " [3, 1754, 38552, 1],\n",
       " [3, 1762, 38552, 1],\n",
       " [4, 1770, 38552, 3],\n",
       " [4, 1774, 38552, 3],\n",
       " [3, 1778, 38552, 1],\n",
       " [3, 1794, 38552, 1],\n",
       " [3, 1810, 38552, 1],\n",
       " [4, 1818, 38552, 3],\n",
       " [3, 1826, 38552, 1],\n",
       " [3, 1834, 38552, 1],\n",
       " [4, 1839, 38552, 3],\n",
       " [3, 1842, 38552, 1],\n",
       " [4, 1850, 38552, 3],\n",
       " [3, 1858, 38552, 1],\n",
       " [3, 1866, 38552, 1],\n",
       " [3, 1882, 38552, 1],\n",
       " [4, 1887, 38552, 3],\n",
       " [3, 1890, 38552, 1],\n",
       " [3, 1898, 38552, 1],\n",
       " [3, 1902, 38552, 1],\n",
       " [3, 1906, 38552, 1],\n",
       " [3, 1922, 38552, 1],\n",
       " [4, 1930, 38552, 3],\n",
       " [3, 1946, 38552, 1],\n",
       " [4, 1951, 38552, 3],\n",
       " [3, 1954, 38552, 1],\n",
       " [3, 1962, 38552, 1],\n",
       " [3, 1970, 38552, 1],\n",
       " [4, 1978, 38552, 3],\n",
       " [4, 1982, 38552, 3],\n",
       " [3, 1994, 38552, 1],\n",
       " [3, 2002, 38552, 1],\n",
       " [3, 2010, 38552, 1],\n",
       " [3, 2026, 38552, 1],\n",
       " [3, 2034, 38552, 1],\n",
       " [5, 2058, 38552, 5],\n",
       " [3, 2066, 38552, 1],\n",
       " [3, 2082, 38552, 1],\n",
       " [3, 2090, 38552, 1],\n",
       " [3, 2098, 38552, 1],\n",
       " [3, 2106, 38552, 1],\n",
       " [3, 2114, 38552, 1],\n",
       " [3, 2122, 38552, 1],\n",
       " [3, 2126, 38552, 1],\n",
       " [3, 2130, 38552, 1],\n",
       " [3, 2138, 38552, 1],\n",
       " [3, 2154, 38552, 1],\n",
       " [3, 2162, 38552, 1],\n",
       " [3, 2170, 38552, 1],\n",
       " [4, 2178, 38552, 3],\n",
       " [4, 2186, 38552, 3],\n",
       " [3, 2194, 38552, 1],\n",
       " [4, 2202, 38552, 3],\n",
       " [4, 2218, 38552, 3],\n",
       " [4, 2223, 38552, 3],\n",
       " [3, 2226, 38552, 1],\n",
       " [4, 2234, 38552, 3],\n",
       " [3, 2242, 38552, 1],\n",
       " [3, 2250, 38552, 1],\n",
       " [3, 2258, 38552, 1],\n",
       " [4, 2266, 38552, 2],\n",
       " [4, 2274, 38552, 3],\n",
       " [4, 2282, 38552, 3],\n",
       " [3, 2290, 38552, 1],\n",
       " [3, 2298, 38552, 1],\n",
       " [4, 2314, 38552, 3],\n",
       " [3, 2322, 38552, 1],\n",
       " [3, 2330, 38552, 1],\n",
       " [3, 2338, 38552, 1],\n",
       " [4, 2346, 38552, 2],\n",
       " [4, 2362, 38552, 3],\n",
       " [3, 2370, 38552, 1],\n",
       " [3, 2378, 38552, 1],\n",
       " [3, 2386, 38552, 1],\n",
       " [4, 2394, 38552, 3],\n",
       " [5, 2403, 38552, 5],\n",
       " [5, 2407, 38552, 4],\n",
       " [4, 2410, 38552, 3],\n",
       " [4, 2415, 38552, 3],\n",
       " [3, 2418, 38552, 1],\n",
       " [3, 2434, 38552, 1],\n",
       " [3, 2442, 38552, 1],\n",
       " [3, 2450, 38552, 1],\n",
       " [3, 2458, 38552, 1],\n",
       " [3, 2466, 38552, 1],\n",
       " [4, 2474, 38552, 3],\n",
       " [3, 2482, 38552, 1],\n",
       " [3, 2490, 38552, 1],\n",
       " [3, 2498, 38552, 1],\n",
       " [4, 2506, 38552, 3],\n",
       " [4, 2510, 38552, 3],\n",
       " [3, 2514, 38552, 1],\n",
       " [4, 2522, 38552, 2],\n",
       " [3, 2530, 38552, 1],\n",
       " [3, 2538, 38552, 1],\n",
       " [3, 2546, 38552, 1],\n",
       " [3, 2562, 38552, 1],\n",
       " [3, 2570, 38552, 1],\n",
       " [4, 2586, 38552, 3],\n",
       " [4, 2590, 38552, 3],\n",
       " [4, 2602, 38552, 3],\n",
       " [4, 2606, 38552, 3],\n",
       " [3, 2610, 38552, 1],\n",
       " [4, 2618, 38552, 3],\n",
       " [4, 2634, 38552, 3],\n",
       " [3, 2642, 38552, 1],\n",
       " [3, 2650, 38552, 1],\n",
       " [3, 2658, 38552, 1],\n",
       " [3, 2666, 38552, 1],\n",
       " [3, 2674, 38552, 1],\n",
       " [3, 2682, 38552, 1],\n",
       " [4, 2686, 38552, 3],\n",
       " [3, 2690, 38552, 1],\n",
       " [4, 2698, 38552, 2],\n",
       " [3, 2706, 38552, 1],\n",
       " [4, 2714, 38552, 3],\n",
       " [3, 2722, 38552, 1],\n",
       " [3, 2730, 38552, 1],\n",
       " [3, 2738, 38552, 1],\n",
       " [4, 2746, 38552, 3],\n",
       " [3, 2754, 38552, 1],\n",
       " [3, 2762, 38552, 1],\n",
       " [3, 2770, 38552, 1],\n",
       " [4, 2778, 38552, 3],\n",
       " [3, 2786, 38552, 1],\n",
       " [4, 2802, 38552, 3],\n",
       " [3, 2810, 38552, 1],\n",
       " [3, 2818, 38552, 1],\n",
       " [3, 2826, 38552, 1],\n",
       " [4, 2830, 38552, 3],\n",
       " [3, 2834, 38552, 1],\n",
       " [3, 2842, 38552, 1],\n",
       " [3, 2850, 38552, 1],\n",
       " [4, 2858, 38552, 3],\n",
       " [3, 2866, 38552, 1],\n",
       " [4, 2874, 38552, 2],\n",
       " [5, 2878, 38552, 4],\n",
       " [3, 2882, 38552, 1],\n",
       " [3, 2890, 38552, 1],\n",
       " [3, 2898, 38552, 1],\n",
       " [4, 2906, 38552, 3],\n",
       " [3, 2914, 38552, 1],\n",
       " [3, 2922, 38552, 1],\n",
       " [3, 2930, 38552, 1],\n",
       " [3, 2938, 38552, 1],\n",
       " [3, 2946, 38552, 1],\n",
       " [4, 2954, 38552, 3],\n",
       " [3, 2962, 38552, 1],\n",
       " [3, 2970, 38552, 1],\n",
       " [3, 2978, 38552, 1],\n",
       " [3, 2986, 38552, 1],\n",
       " [3, 2994, 38552, 1],\n",
       " [4, 3002, 38552, 3],\n",
       " [3, 3010, 38552, 1],\n",
       " [4, 3022, 38552, 3],\n",
       " [3, 3026, 38552, 1],\n",
       " [4, 3030, 38552, 3],\n",
       " [3, 3034, 38552, 1],\n",
       " [3, 3042, 38552, 1],\n",
       " [4, 3050, 38552, 3],\n",
       " [4, 3055, 38552, 3],\n",
       " [3, 3058, 38552, 1],\n",
       " [3, 3074, 38552, 1],\n",
       " [3, 3082, 38552, 1],\n",
       " [3, 3090, 38552, 1],\n",
       " [3, 3098, 38552, 1],\n",
       " [3, 3106, 38552, 1],\n",
       " [4, 3114, 38552, 3],\n",
       " [4, 3118, 38552, 3],\n",
       " [3, 3122, 38552, 1],\n",
       " [3, 3130, 38552, 1],\n",
       " [3, 3138, 38552, 1],\n",
       " [4, 3146, 38552, 3],\n",
       " [3, 3162, 38552, 1],\n",
       " [4, 3166, 38552, 3],\n",
       " [3, 3170, 38552, 1],\n",
       " [3, 3178, 38552, 1],\n",
       " [3, 3182, 38552, 1],\n",
       " [3, 3186, 38552, 1],\n",
       " [3, 3202, 38552, 1],\n",
       " [4, 3210, 38552, 3],\n",
       " [4, 3214, 38552, 3],\n",
       " [3, 3218, 38552, 1],\n",
       " [3, 3226, 38552, 1],\n",
       " [3, 3230, 38552, 1],\n",
       " [3, 3242, 38552, 1],\n",
       " [5, 3246, 38552, 5],\n",
       " [5, 14, 38552, 2],\n",
       " [5, 16, 38552, 2],\n",
       " [5, 20, 38552, 2],\n",
       " [5, 22, 38552, 3],\n",
       " [5, 24, 38552, 2],\n",
       " [5, 28, 38552, 2],\n",
       " [4, 32, 38552, 1],\n",
       " [5, 40, 38552, 2],\n",
       " [5, 44, 38552, 2],\n",
       " [5, 46, 38552, 2],\n",
       " [5, 48, 38552, 2],\n",
       " [5, 52, 38552, 2],\n",
       " [5, 54, 38552, 2],\n",
       " [4, 56, 38552, 1],\n",
       " [5, 60, 38552, 2],\n",
       " [5, 62, 38552, 2],\n",
       " [5, 64, 38552, 2],\n",
       " [4, 72, 38552, 1],\n",
       " [5, 76, 38552, 2],\n",
       " [5, 78, 38552, 2],\n",
       " [5, 80, 38552, 2],\n",
       " [5, 84, 38552, 2],\n",
       " [5, 88, 38552, 2],\n",
       " [5, 96, 38552, 2],\n",
       " [5, 104, 38552, 2],\n",
       " [5, 108, 38552, 2],\n",
       " [5, 110, 38552, 2],\n",
       " [5, 112, 38552, 2],\n",
       " [5, 116, 38552, 2],\n",
       " [5, 118, 38552, 2],\n",
       " [5, 120, 38552, 2],\n",
       " [5, 124, 38552, 2],\n",
       " [5, 126, 38552, 2],\n",
       " [5, 128, 38552, 2],\n",
       " [4, 136, 38552, 1],\n",
       " [5, 140, 38552, 2],\n",
       " [4, 144, 38552, 1],\n",
       " [5, 150, 38552, 2],\n",
       " [5, 152, 38552, 2],\n",
       " [5, 156, 38552, 2],\n",
       " [5, 158, 38552, 2],\n",
       " [5, 160, 38552, 2],\n",
       " [4, 168, 38552, 1],\n",
       " [5, 172, 38552, 2],\n",
       " [4, 174, 38552, 1],\n",
       " [4, 176, 38552, 1],\n",
       " [4, 184, 38552, 1],\n",
       " [5, 188, 38552, 2],\n",
       " [4, 190, 38552, 1],\n",
       " [5, 192, 38552, 2],\n",
       " [5, 196, 38552, 2],\n",
       " [5, 198, 38552, 2],\n",
       " [5, 200, 38552, 2],\n",
       " [5, 204, 38552, 2],\n",
       " [5, 208, 38552, 2],\n",
       " [5, 216, 38552, 2],\n",
       " [5, 224, 38552, 2],\n",
       " [4, 232, 38552, 1],\n",
       " [5, 244, 38552, 2],\n",
       " [5, 248, 38552, 2],\n",
       " [5, 252, 38552, 2],\n",
       " [5, 256, 38552, 2],\n",
       " [4, 264, 38552, 1],\n",
       " [5, 272, 38552, 2],\n",
       " [5, 276, 38552, 2],\n",
       " [5, 278, 38552, 2],\n",
       " [5, 280, 38552, 2],\n",
       " [4, 286, 38552, 1],\n",
       " [4, 288, 38552, 1],\n",
       " [5, 296, 38552, 2],\n",
       " [5, 300, 38552, 2],\n",
       " [4, 312, 38552, 1],\n",
       " [5, 316, 38552, 2],\n",
       " [5, 319, 38552, 3],\n",
       " [5, 328, 38552, 2],\n",
       " [5, 332, 38552, 2],\n",
       " [5, 334, 38552, 2],\n",
       " [4, 336, 38552, 1],\n",
       " [5, 340, 38552, 2],\n",
       " [5, 344, 38552, 2],\n",
       " [5, 348, 38552, 2],\n",
       " [4, 356, 38552, 1],\n",
       " [5, 360, 38552, 2],\n",
       " [5, 364, 38552, 2],\n",
       " [5, 368, 38552, 2],\n",
       " [5, 372, 38552, 2],\n",
       " [5, 376, 38552, 2],\n",
       " [5, 380, 38552, 2],\n",
       " [5, 382, 38552, 2],\n",
       " [5, 384, 38552, 2],\n",
       " [4, 392, 38552, 1],\n",
       " [5, 396, 38552, 2],\n",
       " [5, 400, 38552, 2],\n",
       " [5, 404, 38552, 2],\n",
       " [5, 412, 38552, 2],\n",
       " [5, 416, 38552, 2],\n",
       " [5, 428, 38552, 2],\n",
       " [5, 432, 38552, 2],\n",
       " [5, 440, 38552, 2],\n",
       " [5, 460, 38552, 2],\n",
       " [5, 464, 38552, 2],\n",
       " [5, 472, 38552, 2],\n",
       " [5, 478, 38552, 2],\n",
       " [5, 480, 38552, 2],\n",
       " [5, 484, 38552, 2],\n",
       " [5, 488, 38552, 2],\n",
       " [4, 496, 38552, 1],\n",
       " [4, 504, 38552, 1],\n",
       " [5, 506, 38552, 2],\n",
       " [5, 508, 38552, 2],\n",
       " [5, 510, 38552, 3],\n",
       " [5, 512, 38552, 2],\n",
       " [4, 520, 38552, 1],\n",
       " [5, 524, 38552, 2],\n",
       " [5, 528, 38552, 2],\n",
       " [5, 532, 38552, 2],\n",
       " [5, 534, 38552, 2],\n",
       " [4, 536, 38552, 1],\n",
       " [5, 544, 38552, 2],\n",
       " [4, 552, 38552, 1],\n",
       " [5, 560, 38552, 2],\n",
       " [5, 572, 38552, 2],\n",
       " [5, 574, 38552, 2],\n",
       " [5, 576, 38552, 2],\n",
       " [4, 584, 38552, 1],\n",
       " [5, 588, 38552, 2],\n",
       " [4, 590, 38552, 1],\n",
       " [4, 592, 38552, 1],\n",
       " [5, 596, 38552, 2],\n",
       " [5, 598, 38552, 2],\n",
       " [5, 600, 38552, 2],\n",
       " [5, 604, 38552, 2],\n",
       " [4, 608, 38552, 1],\n",
       " [5, 616, 38552, 2],\n",
       " [5, 620, 38552, 2],\n",
       " [5, 622, 38552, 2],\n",
       " [4, 624, 38552, 1],\n",
       " [5, 632, 38552, 2],\n",
       " [4, 638, 38552, 1],\n",
       " [5, 640, 38552, 2],\n",
       " [5, 648, 38552, 2],\n",
       " [5, 655, 38552, 3],\n",
       " [5, 664, 38552, 2],\n",
       " [4, 672, 38552, 1],\n",
       " [4, 680, 38552, 1],\n",
       " [5, 684, 38552, 2],\n",
       " [4, 688, 38552, 1],\n",
       " [5, 692, 38552, 2],\n",
       " [4, 696, 38552, 1],\n",
       " [5, 700, 38552, 2],\n",
       " [5, 702, 38552, 2],\n",
       " [4, 704, 38552, 1],\n",
       " [4, 712, 38552, 1],\n",
       " [5, 716, 38552, 2],\n",
       " [5, 720, 38552, 2],\n",
       " [4, 728, 38552, 1],\n",
       " [5, 732, 38552, 2],\n",
       " [4, 734, 38552, 1],\n",
       " [4, 736, 38552, 1],\n",
       " [5, 744, 38552, 2],\n",
       " [5, 752, 38552, 2],\n",
       " [5, 760, 38552, 2],\n",
       " [5, 768, 38552, 2],\n",
       " [5, 776, 38552, 2],\n",
       " [5, 780, 38552, 2],\n",
       " [5, 784, 38552, 2],\n",
       " [5, 792, 38552, 2],\n",
       " [5, 800, 38552, 2],\n",
       " [5, 804, 38552, 2],\n",
       " [5, 808, 38552, 2],\n",
       " [5, 812, 38552, 2],\n",
       " [5, 816, 38552, 2],\n",
       " [5, 820, 38552, 2],\n",
       " [5, 824, 38552, 2],\n",
       " [5, 828, 38552, 2],\n",
       " [4, 832, 38552, 1],\n",
       " [4, 840, 38552, 1],\n",
       " [4, 848, 38552, 1],\n",
       " [4, 856, 38552, 1],\n",
       " [5, 860, 38552, 2],\n",
       " [5, 862, 38552, 2],\n",
       " [4, 864, 38552, 1],\n",
       " [5, 868, 38552, 2],\n",
       " [5, 872, 38552, 2],\n",
       " [5, 876, 38552, 2],\n",
       " [5, 884, 38552, 2],\n",
       " [5, 888, 38552, 2],\n",
       " [5, 896, 38552, 2],\n",
       " [4, 904, 38552, 1],\n",
       " [4, 912, 38552, 1],\n",
       " [4, 924, 38552, 1],\n",
       " [5, 928, 38552, 2],\n",
       " [5, 932, 38552, 2],\n",
       " [5, 936, 38552, 2],\n",
       " [5, 940, 38552, 2],\n",
       " [5, 944, 38552, 2],\n",
       " [4, 952, 38552, 1],\n",
       " [5, 958, 38552, 3],\n",
       " [5, 960, 38552, 2],\n",
       " [5, 964, 38552, 2],\n",
       " [5, 968, 38552, 2],\n",
       " [5, 972, 38552, 2],\n",
       " [5, 980, 38552, 2],\n",
       " [4, 984, 38552, 1],\n",
       " [5, 988, 38552, 2],\n",
       " [5, 991, 38552, 4],\n",
       " [5, 996, 38552, 2],\n",
       " [5, 1000, 38552, 2],\n",
       " [5, 1004, 38552, 2],\n",
       " [5, 1008, 38552, 2],\n",
       " [4, 1016, 38552, 1],\n",
       " [4, 1022, 38552, 1],\n",
       " [5, 1024, 38552, 2],\n",
       " [4, 1032, 38552, 1],\n",
       " [5, 1040, 38552, 2],\n",
       " [5, 1044, 38552, 2],\n",
       " [5, 1048, 38552, 2],\n",
       " [5, 1052, 38552, 2],\n",
       " [5, 1056, 38552, 2],\n",
       " [4, 1064, 38552, 1],\n",
       " [4, 1070, 38552, 1],\n",
       " [4, 1072, 38552, 1],\n",
       " [5, 1080, 38552, 2],\n",
       " [5, 1088, 38552, 2],\n",
       " [5, 1096, 38552, 2],\n",
       " [5, 1100, 38552, 2],\n",
       " [5, 1108, 38552, 2],\n",
       " [5, 1112, 38552, 2],\n",
       " [5, 1144, 38552, 2],\n",
       " [5, 1148, 38552, 2],\n",
       " [4, 1152, 38552, 1],\n",
       " [4, 1160, 38552, 1],\n",
       " [5, 1164, 38552, 2],\n",
       " [5, 1168, 38552, 2],\n",
       " [4, 1176, 38552, 1],\n",
       " [4, 1184, 38552, 1],\n",
       " [5, 1188, 38552, 2],\n",
       " [5, 1192, 38552, 2],\n",
       " [5, 1200, 38552, 2],\n",
       " [5, 1204, 38552, 2],\n",
       " [4, 1208, 38552, 1],\n",
       " [4, 1212, 38552, 1],\n",
       " [5, 1215, 38552, 3],\n",
       " [5, 1224, 38552, 2],\n",
       " [5, 1228, 38552, 2],\n",
       " [5, 1230, 38552, 2],\n",
       " [5, 1232, 38552, 2],\n",
       " [4, 1240, 38552, 1],\n",
       " [5, 1248, 38552, 2],\n",
       " [5, 1252, 38552, 2],\n",
       " [5, 1255, 38552, 3],\n",
       " [5, 1260, 38552, 2],\n",
       " [5, 1264, 38552, 2],\n",
       " [4, 1272, 38552, 1],\n",
       " [5, 1279, 38552, 3],\n",
       " [5, 1288, 38552, 2],\n",
       " [5, 1292, 38552, 2],\n",
       " [5, 1296, 38552, 2],\n",
       " [4, 1304, 38552, 1],\n",
       " [5, 1308, 38552, 2],\n",
       " [5, 1310, 38552, 2],\n",
       " [5, 1312, 38552, 2],\n",
       " [4, 1320, 38552, 1],\n",
       " [5, 1324, 38552, 2],\n",
       " [5, 1328, 38552, 2],\n",
       " [4, 1336, 38552, 1],\n",
       " [5, 1340, 38552, 2],\n",
       " [5, 1342, 38552, 3],\n",
       " [5, 1344, 38552, 2],\n",
       " [4, 1352, 38552, 1],\n",
       " [5, 1356, 38552, 2],\n",
       " [5, 1358, 38552, 2],\n",
       " [5, 1360, 38552, 2],\n",
       " [5, 1364, 38552, 2],\n",
       " [5, 1368, 38552, 2],\n",
       " [5, 1372, 38552, 2],\n",
       " [4, 1374, 38552, 1],\n",
       " [4, 1376, 38552, 1],\n",
       " [4, 1384, 38552, 1],\n",
       " [4, 1390, 38552, 1],\n",
       " [5, 1392, 38552, 2],\n",
       " [5, 1396, 38552, 2],\n",
       " [4, 1400, 38552, 1],\n",
       " [5, 1404, 38552, 2],\n",
       " [5, 1406, 38552, 2],\n",
       " [5, 1408, 38552, 2],\n",
       " [5, 1416, 38552, 2],\n",
       " [5, 1420, 38552, 2],\n",
       " [5, 1422, 38552, 3],\n",
       " [5, 1424, 38552, 2],\n",
       " [4, 1432, 38552, 1],\n",
       " [5, 1440, 38552, 2],\n",
       " [5, 1444, 38552, 2],\n",
       " [5, 1448, 38552, 2],\n",
       " [5, 1452, 38552, 2],\n",
       " [5, 1454, 38552, 2],\n",
       " [5, 1456, 38552, 2],\n",
       " [4, 1464, 38552, 1],\n",
       " [4, 1472, 38552, 1],\n",
       " [5, 1476, 38552, 2],\n",
       " [5, 1480, 38552, 2],\n",
       " [5, 1488, 38552, 2],\n",
       " [5, 1496, 38552, 2],\n",
       " [5, 1500, 38552, 2],\n",
       " [5, 1504, 38552, 2],\n",
       " [4, 1512, 38552, 1],\n",
       " [5, 1516, 38552, 2],\n",
       " [5, 1520, 38552, 2],\n",
       " [4, 1528, 38552, 1],\n",
       " [5, 1532, 38552, 2],\n",
       " [4, 1544, 38552, 1],\n",
       " [5, 1548, 38552, 2],\n",
       " [4, 1550, 38552, 1],\n",
       " [4, 1552, 38552, 1],\n",
       " [5, 1560, 38552, 2],\n",
       " [5, 1568, 38552, 2],\n",
       " [4, 1576, 38552, 1],\n",
       " [5, 1582, 38552, 2],\n",
       " [4, 1584, 38552, 1],\n",
       " [5, 1588, 38552, 2],\n",
       " [5, 1590, 38552, 2],\n",
       " [5, 1592, 38552, 2],\n",
       " [5, 1596, 38552, 2],\n",
       " [4, 1600, 38552, 1],\n",
       " [4, 1608, 38552, 1],\n",
       " [5, 1612, 38552, 2],\n",
       " [5, 1614, 38552, 2],\n",
       " [5, 1616, 38552, 2],\n",
       " [5, 1620, 38552, 2],\n",
       " [5, 1624, 38552, 2],\n",
       " [5, 1632, 38552, 2],\n",
       " [5, 1640, 38552, 2],\n",
       " [5, 1644, 38552, 2],\n",
       " [4, 1648, 38552, 1],\n",
       " [5, 1656, 38552, 2],\n",
       " [5, 1664, 38552, 2],\n",
       " [4, 1672, 38552, 1],\n",
       " [5, 1676, 38552, 2],\n",
       " [4, 1680, 38552, 1],\n",
       " [4, 1688, 38552, 1],\n",
       " [5, 1695, 38552, 3],\n",
       " [5, 1704, 38552, 2],\n",
       " [5, 1708, 38552, 2],\n",
       " [4, 1712, 38552, 1],\n",
       " [5, 1720, 38552, 2],\n",
       " [4, 1728, 38552, 1],\n",
       " [4, 1736, 38552, 1],\n",
       " [5, 1740, 38552, 2],\n",
       " [5, 1752, 38552, 2],\n",
       " [5, 1760, 38552, 2],\n",
       " [5, 1764, 38552, 2],\n",
       " [4, 1768, 38552, 1],\n",
       " [5, 1772, 38552, 2],\n",
       " [5, 1776, 38552, 2],\n",
       " [5, 1784, 38552, 2],\n",
       " [4, 1790, 38552, 1],\n",
       " [4, 1792, 38552, 1],\n",
       " [5, 1800, 38552, 2],\n",
       " [5, 1806, 38552, 2],\n",
       " [5, 1808, 38552, 2],\n",
       " [5, 1816, 38552, 2],\n",
       " [5, 1820, 38552, 2],\n",
       " [5, 1823, 38552, 3],\n",
       " [5, 1828, 38552, 2],\n",
       " [5, 1832, 38552, 2],\n",
       " [5, 1836, 38552, 2],\n",
       " [5, 1844, 38552, 2],\n",
       " [5, 1848, 38552, 2],\n",
       " [5, 1852, 38552, 2],\n",
       " [5, 1856, 38552, 2],\n",
       " [5, 1860, 38552, 2],\n",
       " [5, 1864, 38552, 2],\n",
       " [5, 1876, 38552, 2],\n",
       " [5, 1880, 38552, 2],\n",
       " [5, 1884, 38552, 2],\n",
       " [4, 1896, 38552, 1],\n",
       " [5, 1904, 38552, 2],\n",
       " [4, 1912, 38552, 1],\n",
       " [5, 1920, 38552, 2],\n",
       " [5, 1928, 38552, 2],\n",
       " [5, 1936, 38552, 2],\n",
       " [4, 1944, 38552, 1],\n",
       " [5, 1948, 38552, 2],\n",
       " [5, 1956, 38552, 2],\n",
       " [4, 1960, 38552, 1],\n",
       " [5, 1964, 38552, 2],\n",
       " [4, 1966, 38552, 1],\n",
       " [4, 1968, 38552, 1],\n",
       " [5, 1976, 38552, 2],\n",
       " [5, 1980, 38552, 2],\n",
       " [5, 1984, 38552, 2],\n",
       " [4, 1992, 38552, 1],\n",
       " [5, 1996, 38552, 2],\n",
       " [5, 1999, 38552, 3],\n",
       " [5, 2004, 38552, 2],\n",
       " [5, 2008, 38552, 2],\n",
       " [5, 2012, 38552, 2],\n",
       " [5, 2014, 38552, 2],\n",
       " [4, 2016, 38552, 1],\n",
       " [5, 2024, 38552, 2],\n",
       " [5, 2031, 38552, 3],\n",
       " [5, 2044, 38552, 2],\n",
       " [5, 2048, 38552, 2],\n",
       " [5, 2056, 38552, 2],\n",
       " [5, 2064, 38552, 2],\n",
       " [5, 2068, 38552, 2],\n",
       " [4, 2072, 38552, 1],\n",
       " [4, 2080, 38552, 1],\n",
       " [5, 2088, 38552, 2],\n",
       " [5, 2092, 38552, 2],\n",
       " [5, 2095, 38552, 3],\n",
       " [5, 2100, 38552, 2],\n",
       " [4, 2104, 38552, 1],\n",
       " [5, 2108, 38552, 2],\n",
       " [5, 2110, 38552, 2],\n",
       " [5, 2112, 38552, 2],\n",
       " [5, 2116, 38552, 2],\n",
       " [4, 2120, 38552, 1],\n",
       " [5, 2128, 38552, 2],\n",
       " [5, 2132, 38552, 2],\n",
       " [5, 2136, 38552, 2],\n",
       " [5, 2140, 38552, 2],\n",
       " [5, 2144, 38552, 2],\n",
       " [4, 2152, 38552, 1],\n",
       " [5, 2160, 38552, 2],\n",
       " [5, 2164, 38552, 2],\n",
       " [5, 2167, 38552, 3],\n",
       " [5, 2172, 38552, 2],\n",
       " [5, 2175, 38552, 3],\n",
       " [5, 2184, 38552, 2],\n",
       " [5, 2188, 38552, 2],\n",
       " [5, 2190, 38552, 2],\n",
       " [4, 2192, 38552, 1],\n",
       " [5, 2196, 38552, 2],\n",
       " [5, 2199, 38552, 3],\n",
       " [4, 2208, 38552, 1],\n",
       " [4, 2214, 38552, 1],\n",
       " [4, 2216, 38552, 1],\n",
       " [5, 2220, 38552, 2],\n",
       " [4, 2232, 38552, 1],\n",
       " [5, 2236, 38552, 2],\n",
       " [4, 2238, 38552, 1],\n",
       " [4, 2240, 38552, 1],\n",
       " [4, 2248, 38552, 1],\n",
       " [5, 2252, 38552, 2],\n",
       " [5, 2255, 38552, 3],\n",
       " [5, 2260, 38552, 2],\n",
       " [5, 2264, 38552, 2],\n",
       " [5, 2272, 38552, 2],\n",
       " [5, 2280, 38552, 2],\n",
       " [5, 2284, 38552, 2],\n",
       " [5, 2288, 38552, 2],\n",
       " [4, 2294, 38552, 1],\n",
       " [5, 2296, 38552, 2],\n",
       " [5, 2304, 38552, 2],\n",
       " [5, 2312, 38552, 2],\n",
       " [5, 2316, 38552, 2],\n",
       " [5, 2320, 38552, 2],\n",
       " [5, 2324, 38552, 2],\n",
       " [5, 2328, 38552, 2],\n",
       " [4, 2334, 38552, 1],\n",
       " [4, 2336, 38552, 1],\n",
       " [5, 2344, 38552, 2],\n",
       " [4, 2348, 38552, 1],\n",
       " [4, 2350, 38552, 1],\n",
       " [4, 2352, 38552, 1],\n",
       " [4, 2360, 38552, 1],\n",
       " [5, 2364, 38552, 2],\n",
       " [5, 2366, 38552, 2],\n",
       " [5, 2368, 38552, 2],\n",
       " [5, 2376, 38552, 2],\n",
       " [4, 2384, 38552, 1],\n",
       " [5, 2388, 38552, 2],\n",
       " [4, 2390, 38552, 1],\n",
       " [5, 2392, 38552, 2],\n",
       " [5, 2396, 38552, 2],\n",
       " [5, 2399, 38552, 4],\n",
       " [5, 2412, 38552, 2],\n",
       " [5, 2420, 38552, 2],\n",
       " [5, 2424, 38552, 2],\n",
       " [5, 2431, 38552, 3],\n",
       " [5, 2440, 38552, 2],\n",
       " [5, 2448, 38552, 2],\n",
       " [5, 2456, 38552, 2],\n",
       " [4, 2464, 38552, 1],\n",
       " [5, 2472, 38552, 2],\n",
       " [5, 2476, 38552, 2],\n",
       " [5, 2479, 38552, 3],\n",
       " [4, 2488, 38552, 1],\n",
       " [5, 2492, 38552, 2],\n",
       " [4, 2494, 38552, 1],\n",
       " [4, 2496, 38552, 1],\n",
       " [4, 2504, 38552, 1],\n",
       " [5, 2508, 38552, 2],\n",
       " [5, 2512, 38552, 2],\n",
       " [4, 2520, 38552, 1],\n",
       " [5, 2524, 38552, 2],\n",
       " [5, 2528, 38552, 2],\n",
       " [5, 2536, 38552, 2],\n",
       " [5, 2540, 38552, 2],\n",
       " [5, 2542, 38552, 2],\n",
       " [5, 2544, 38552, 2],\n",
       " [4, 2552, 38552, 1],\n",
       " [5, 2560, 38552, 2],\n",
       " [5, 2568, 38552, 2],\n",
       " [4, 2576, 38552, 1],\n",
       " [5, 2580, 38552, 2],\n",
       " [5, 2584, 38552, 2],\n",
       " [5, 2588, 38552, 2],\n",
       " [4, 2592, 38552, 1],\n",
       " [5, 2600, 38552, 2],\n",
       " [5, 2604, 38552, 2],\n",
       " [4, 2608, 38552, 1],\n",
       " [5, 2612, 38552, 2],\n",
       " [5, 2616, 38552, 2],\n",
       " [5, 2620, 38552, 2],\n",
       " [5, 2622, 38552, 2],\n",
       " [4, 2624, 38552, 1],\n",
       " [5, 2632, 38552, 2],\n",
       " [5, 2636, 38552, 2],\n",
       " [5, 2638, 38552, 2],\n",
       " [5, 2640, 38552, 2],\n",
       " [5, 2644, 38552, 2],\n",
       " [5, 2646, 38552, 2],\n",
       " [4, 2648, 38552, 1],\n",
       " [4, 2656, 38552, 1],\n",
       " [4, 2664, 38552, 1],\n",
       " [5, 2668, 38552, 2],\n",
       " [5, 2670, 38552, 2],\n",
       " [5, 2672, 38552, 2],\n",
       " [5, 2676, 38552, 2],\n",
       " [5, 2680, 38552, 2],\n",
       " [5, 2684, 38552, 2],\n",
       " [5, 2688, 38552, 2],\n",
       " [4, 2696, 38552, 1],\n",
       " [4, 2704, 38552, 1],\n",
       " [5, 2712, 38552, 2],\n",
       " [5, 2716, 38552, 2],\n",
       " [5, 2718, 38552, 2],\n",
       " [4, 2720, 38552, 1],\n",
       " [5, 2724, 38552, 2],\n",
       " [5, 2728, 38552, 2],\n",
       " [4, 2736, 38552, 1],\n",
       " [4, 2744, 38552, 1],\n",
       " [5, 2748, 38552, 2],\n",
       " [5, 2752, 38552, 2],\n",
       " [5, 2756, 38552, 2],\n",
       " [4, 2760, 38552, 1],\n",
       " [4, 2768, 38552, 1],\n",
       " [4, 2776, 38552, 1],\n",
       " [5, 2780, 38552, 2],\n",
       " [5, 2782, 38552, 2],\n",
       " [5, 2784, 38552, 2],\n",
       " [5, 2788, 38552, 2],\n",
       " [5, 2790, 38552, 2],\n",
       " [5, 2792, 38552, 2],\n",
       " [5, 2799, 38552, 3],\n",
       " [5, 2808, 38552, 2],\n",
       " [5, 2812, 38552, 2],\n",
       " [4, 2814, 38552, 1],\n",
       " [5, 2816, 38552, 2],\n",
       " [4, 2824, 38552, 1],\n",
       " [5, 2828, 38552, 2],\n",
       " [5, 2832, 38552, 2],\n",
       " [5, 2836, 38552, 2],\n",
       " [4, 2838, 38552, 1],\n",
       " [4, 2840, 38552, 1],\n",
       " [5, 2844, 38552, 2],\n",
       " [5, 2846, 38552, 2],\n",
       " [5, 2848, 38552, 2],\n",
       " [5, 2852, 38552, 2],\n",
       " [5, 2854, 38552, 2],\n",
       " [5, 2856, 38552, 2],\n",
       " [5, 2860, 38552, 2],\n",
       " [5, 2862, 38552, 2],\n",
       " [5, 2864, 38552, 2],\n",
       " [4, 2872, 38552, 1],\n",
       " [5, 2876, 38552, 2],\n",
       " [5, 2880, 38552, 2],\n",
       " [5, 2884, 38552, 2],\n",
       " [5, 2886, 38552, 2],\n",
       " [4, 2888, 38552, 1],\n",
       " [5, 2894, 38552, 2],\n",
       " [5, 2896, 38552, 2],\n",
       " [5, 2900, 38552, 2],\n",
       " [5, 2904, 38552, 2],\n",
       " [5, 2908, 38552, 2],\n",
       " [5, 2910, 38552, 2],\n",
       " [4, 2912, 38552, 1],\n",
       " [5, 2916, 38552, 2],\n",
       " [4, 2920, 38552, 1],\n",
       " [4, 2926, 38552, 1],\n",
       " [4, 2928, 38552, 1],\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_coors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78acf33c-fef6-4a2a-8393-792f029d0760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holodec",
   "language": "python",
   "name": "holodec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
